{
 "metadata": {
  "name": "Idomaar Workshop"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Basic Tutorial"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## textFile allows to read a local, s3 or hdfs file. It is not an action\nreadFile = sc.textFile('/opt/tmp/movietweeting/evaluation/split/method_rnd_value_0.75_from_10_to_100/train/relation.dat')\nprint readFile",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "/vagrant/data/movietweeting/evaluation/split/method_rnd_value_0.75_from_10_to_100/train/relation.dat MappedRDD[3] at textFile at NativeMethodAccessorImpl.java:-2\n"
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## To see what we have read, we need an action such as \"first()\". \n## Using first we can visualize the first line of the read file.\nprint readFile.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "rating.explicit\t9144\t1362062838\t{\"rating\":6}\t{\"subject\":\"user:3462\",\"object\":\"movie:1411238\"}\n"
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## map applies a function to  each line of the RDD one by one. \n## Inn this example, it applies a \"split(\"\\t\")\" function.\n## Thus we start with a String and we end up with a list of string.\n## Map is an action, thus it takes as input an RDD and return another one.\n## We want to remove the end of file line from the file. Thus we use the filter to remove it.\nparsedDataRDD = readFile.filter(lambda x: \"EOF\" not in x).map(lambda x: x.split(\"\\t\"))\nprint parsedDataRDD",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "PythonRDD[19] at RDD at PythonRDD.scala:43\n"
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print parsedDataRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[u'rating.explicit', u'9144', u'1362062838', u'{\"rating\":6}', u'{\"subject\":\"user:3462\",\"object\":\"movie:1411238\"}']\n"
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## We want to count the distinct number of users. \n## Thus we need to extract the username, use the distinct() transformation and count() the result\nimport json\ndef readJson(data,field):\n    return json.loads(data)[field]\nusersRDD = parsedDataRDD.map(lambda x: readJson(x[4],\"subject\"))\nprint usersRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "user:3462\n"
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "numberOfUsers = usersRDD.distinct().count()\nprint \"There are\",numberOfUsers,\"distinct users!!\"",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "There are 122 distinct users\n"
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## We want to extract the most popular movie.\n## We need to use reduceByKey but it needs a PairRDD: lets build it!\nmovieRDD = parsedDataRDD.map(lambda x: (readJson(x[4],\"object\"),1))\nprint movieRDD.first(),\"where\", \"'\"+movieRDD.first()[0]+\"'\", \"is the key and\", \"'\"+str(movieRDD.first()[1])+\"'\",\"is a 'fake' value\"\n\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " (u'movie:1411238', 1) where 'movie:1411238' is the key and "
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "'1' is a 'fake' value\n"
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## We use the fake value '1' because reducing by key using the movieId key summing up every '1' \n## will give back the times each movie is consumed\n## ReduceByKey works this way:\n## it finds a couple of line with the same key T1 = (k1,x)      T2 = (k2,y)\n## it combine the values with a specified function, in the example it sums them returning a new line T3 = (k1, x+y).\n## It goes on until there are no more lines with the same key.\n## Using top we can extract the top lines\n\nmovieRDD.reduceByKey(lambda x,y: x+y).top(5,key=lambda x: x[1])",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": "[(u'movie:1623205', 13),\n (u'movie:1024648', 11),\n (u'movie:1790885', 10),\n (u'movie:1907668', 9),\n (u'movie:1707386', 8)]"
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Advanced Tutorial: collaborative filtering with Spark!!!"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Initialization: base methods"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## We need to create a reduceByKey function that allows us to append the values in a list.\n## To do that, first we need to transform each value in a list with only one element, the value itself.\n## We use map(lambda x: createList(x)) for this purpose.\n## To append each value of each list to the others, we use lambdalist.\n## We need to do that because we cannot know the \"state\" of each line during a reduceByKey.\n\ndef create_list(value, count=1):\n    result = list()\n    for k in range(count):\n        result.append(value)\n    return result\n\ndef lambdalist(x,y):\n    for k in x:\n        y.append(k)\n    return y\n\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Computation of the cosine similarity values for each couple of movies"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Creation of the normalization matrix"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import numpy as np\n## norm(line) = sqrt ( sum ( a_i ^2)) for a_i from line\nnormMatrixRDD = parsedDataRDD.map(lambda x: (readJson(x[4],'object'),readJson(x[3],'rating')))\\ ## parse the matrix in a handle way\n                    .map(lambda x: (x[0], x[1]*x[1]))\\ ## compute the square\n                    .reduceByKey(lambda x,y: x+y)\\ ## sum each square\n                    .map(lambda x: (x[0],np.sqrt(x[1]))) ## sqrt of each sum\n\n\nnormMatrixRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": "(u'movie:1216492', 7.0)"
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## I need to parse the data in a smart way to compute the normalised value through a join\nsparseMatrixRDDelements = parsedDataRDD.map(lambda x: (readJson(x[4],'object'),(readJson(x[4],'subject'),readJson(x[3],'rating'))))\nsparseMatrixRDDelements.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": "(u'movie:1411238', (u'user:3462', 6))"
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Computing the normalised sparse matrix (user, item, norm_rating)"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## first I join each element of the matrix with the normalised RDD.\n## This way in the same line of the RDD we will have the userId, the itemId, the user rating and the norm value.\nnormSparseMatrixRDDelements = sparseMatrixRDDelements.join(normMatrixRDD)   \nnormSparseMatrixRDDelements.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": "(u'movie:0108255', ((u'user:1612', 2), 2.0))"
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## then, we compute the normalised value as rating / (shrink value + norm)\nshrink = 0.5\nnormSparseMatrixRDDelements = sparseMatrixRDDelements.join(normMatrixRDD)\\\n                                .map(lambda x: (x[0], (x[1][0][0], x[1][0][1] / (shrink + x[1][1] ))))\nnormSparseMatrixRDDelements.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": "(u'movie:0108255', (u'user:1612', 0.80000000000000004))"
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Compute the cosine similarity in a disaggregated way"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## first we make the cartesian product between each element of the normalised sparse matrix with theirselves\nitem_itemRDD = normSparseMatrixRDDelements.cartesian(normSparseMatrixRDDelements)\nitem_itemRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": "((u'movie:0108255', (u'user:1612', 0.80000000000000004)),\n (u'movie:0108255', (u'user:1612', 0.80000000000000004)))"
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## second, we filter out rating on the same movie or on different movie by different users.\n## We need to sum the multiplication of each couple of rating of the same user on different movies. \nitem_itemRDD = normSparseMatrixRDDelements.cartesian(normSparseMatrixRDDelements)\\\n        .filter(lambda x: x[0][0] != x[1][0] and x[0][1][0] == x[1][1][0])\n\nitem_itemRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": "((u'movie:0108255', (u'user:1612', 0.80000000000000004)),\n (u'movie:0277371', (u'user:1612', 0.92307692307692313)))"
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## once we selected the right commutations, we multiplicate the normalised ratings and sum all the values with reduceByKey\nitem_itemRDDelements = normSparseMatrixRDDelements.cartesian(normSparseMatrixRDDelements)\\\n        .filter(lambda x: x[0][0] != x[1][0] and x[0][1][0] == x[1][1][0])\\\n        .map(lambda x: (x[0][0]+\"_\"+x[1][0], x[0][1][1] * x[1][1][1]))\\\n        .reduceByKey(lambda x,y: x+y)\n\nitem_itemRDDelements.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 96,
       "text": "(u'movie:0446029_movie:0445934', 0.45939827362758329)"
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## in the end, we group results to have (movie_i, [movie_j, cos_sim(movie_i,movie_j)])\ncosSimilaritiesRDD = item_itemRDDelements.reduceByKey(lambda x,y: x+y)\\\n            .map(lambda x: (x[0].split(\"_\")[0],(x[0].split(\"_\")[1],x[1])))\\\n            ##.map(lambda x: (x[0].split(\"_\")[0],create_list((x[0].split(\"_\")[1],x[1]))))\\\n            ##.reduceByKey(lambda x,y: lambdalist(x,y))\ncosSimilaritiesRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 128,
       "text": "(u'movie:0446029', (u'movie:0445934', 0.45939827362758329))"
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Recommendation"
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "A baisc way to use the cosine similarity is to dot product the rating vector of each user with the cosine similarity matrix, rank the results and recommend the top n movies.\nThus\n1) we need to collect user ratings in the train set\n2) we need to compute the dot product\n3) we need to extract the top n\n4) we need to evaluate the recommendation with the test set"
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Parsing again the train set"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## We need to create this structure\n## userId, [(movie1, rating1),...], set(movie1,..)\n## We need to know each rating for the dot product and the set of watched movies to avoid to recommend already seen movies\n\ndef create_Dict(x,pos=1,key=0,value=1):\n    dic = {}\n    for el in x[pos]:\n        dic[el[key]] = el[value]\n    return dic\n\n\n    \nuserEventRDD = parsedDataRDD.map(lambda x: (readJson(x[4], 'subject'),create_list((readJson(x[4], 'object')\n                                                                                   ,readJson(x[3], 'rating')))))\\\n                            .reduceByKey(lambda x,y: lambdalist(x,y))\\\n                            .map(lambda x: (x[0],( create_Dict(x))))\nuserEventRDD.persist()              \na = userEventRDD.collect()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "recommendationRDD = userEventRDD.cartesian(cosSimilaritiesRDD)\nrecommendationRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 146,
       "text": "((u'user:1612',\n  {u'movie:0071571': 8,\n   u'movie:0079073': 1,\n   u'movie:0108255': 2,\n   u'movie:0187078': 7,\n   u'movie:0277371': 6,\n   u'movie:0390521': 4,\n   u'movie:0450259': 10,\n   u'movie:0497373': 8,\n   u'movie:0867271': 1,\n   u'movie:1409024': 8}),\n (u'movie:0446029', (u'movie:0445934', 0.45939827362758329)))"
      }
     ],
     "prompt_number": 146
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "The cartesian product create an RDD with this structure:\nmovie = x[1][0]\nuser = x[0][0]\nalreadyWatchedMovies = x[0][1][1]\nratingList = x[0][1][0]\ncosList = x[1][1]"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def takeTopN(x, n=25):\n    a = x[1]\n    if len(a) < n: n = len(a)\n    return sorted(a, key=lambda x: -x[1])[0:n] \n    \ndef flattener(x):\n    result = list()\n    for k in x[1]:\n        result.append((x[0],k))\n    return result\n\nrecommendationRDD = userEventRDD.cartesian(cosSimilaritiesRDD).filter(lambda x: x[1][0] not in x[0][1] and x[1][1][0] in x[0][1])\\\n                                .map(lambda x: (x[0][0]+\"_\"+x[1][0],x[1][1][1] * x[0][1][x[1][1][0]]))\\\n                                .reduceByKey(lambda x,y: x+y)\\\n                                .map(lambda x: (x[0].split(\"_\")[0],create_list((x[0].split(\"_\")[1],x[1]))))\\\n                                .reduceByKey(lambda x,y: lambdalist(x,y)).map(lambda x: (x[0],takeTopN(x)))\\\n                                .map(lambda x: (flattener(x))).flatMap(lambda x: x)\n                \n\nrecommendationRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 175,
       "text": "(u'user:1340', (u'movie:0399295', 5.6957807324408529))"
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Reading and parsing test file"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "readFileTest = sc.textFile('/opt/tmp/movietweeting/evaluation/split/method_rnd_value_0.75_from_10_to_100/test/relation.dat')\nparsedDataTestRDD = readFileTest.filter(lambda x: \"EOF\" not in x).map(lambda x: x.split(\"\\t\"))\\\n                                .map(lambda x: (readJson(x[4],'subject'),(readJson(x[4],'object'),readJson(x[3],'rating'))))\nparsedDataTestRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 176,
       "text": "(u'user:32', (u'movie:0118799', 5))"
      }
     ],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "recommendationsHitsRDD = parsedDataTestRDD.join(recommendationRDD).filter(lambda x: x[1][0][0] == x[1][1][0])\\\n            .map(lambda x: (x[0],1)).reduceByKey(lambda x,y: x+y )\nrecommendationsHitsRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 185,
       "text": "(u'user:1674', 1)"
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "userEventsRDD = parsedDataTestRDD.map(lambda x: (x[0],1)).reduceByKey(lambda x,y: x+y)\nuserEventsRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 186,
       "text": "(u'user:1340', 4)"
      }
     ],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "recallRDD = userEventsRDD.join(recommendationsHitsRDD).map(lambda x: float(x[1][1])/x[1][0])\nrecallAtN = recallRDD.sum()/recallRDD.count()\nprint \"Recall:\",recallAtN",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "0.253216374269\n"
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "recomCountRDD = recommendationRDD.map(lambda x: (x[0],1)).reduceByKey(lambda x,y: x+y)\nrecomCountRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 194,
       "text": "(u'user:1340', 25)"
      }
     ],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "precisionRDD = recomCountRDD.join(recommendationsHitsRDD).map(lambda x: float(x[1][1])/x[1][0])\nprecision = precisionRDD.sum()/precisionRDD.count()\nprint \"Precision:\",precision",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Precision: 0.0466666666667\n"
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
