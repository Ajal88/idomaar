{
 "metadata": {
  "name": "Idomaar Workshop advanced exercise"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Basic Tutorial"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## textFile allows to read a local, s3 or hdfs file. It is not an action\nreadFile = sc.textFile('/vagrant/data/movietweeting/evaluation/split/method_rnd_value_0.75_from_10_to_100/train/relation.dat')\nprint readFile",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "/opt/tmp/movietweeting/evaluation/split/method_rnd_value_0.75_from_10_to_100/train/relation.dat MappedRDD[1] at textFile at NativeMethodAccessorImpl.java:-2\n"
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## To see what we have read, we need an action such as \"first()\". \n## Using first we can visualize the first line of the read file.\nprint readFile.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "rating.explicit\t9144\t1362062838\t{\"rating\":6}\t{\"subject\":\"user:3462\",\"object\":\"movie:1411238\"}\n"
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## map applies a function to  each line of the RDD one by one. \n## Inn this example, it applies a \"split(\"\\t\")\" function.\n## Thus we start with a String and we end up with a list of string.\n## Map is an action, thus it takes as input an RDD and return another one.\n## We want to remove the end of file line from the file. Thus we use the filter to remove it.\nparsedDataRDD = readFile.filter(lambda x: \"EOF\" not in x).map(lambda x: x.split(\"\\t\"))\nprint parsedDataRDD",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "PythonRDD[3] at RDD at PythonRDD.scala:43\n"
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print parsedDataRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[u'rating.explicit', u'9144', u'1362062838', u'{\"rating\":6}', u'{\"subject\":\"user:3462\",\"object\":\"movie:1411238\"}']\n"
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## We want to count the distinct number of users. \n## Thus we need to extract the username, use the distinct() transformation and count() the result\nimport json\ndef readJson(data,field):\n    return json.loads(data)[field]\nusersRDD = parsedDataRDD.map(lambda x: readJson(x[4],\"subject\"))\nprint usersRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "user:3462\n"
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "numberOfUsers = usersRDD.distinct().count()\nprint \"There are\",numberOfUsers,\"distinct users!!\"",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "There are 122 distinct users!!\n"
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## We want to extract the most popular movie.\n## We need to use reduceByKey but it needs a PairRDD: lets build it!\nmovieRDD = parsedDataRDD.map(lambda x: (readJson(x[4],\"object\"),1))\nprint movieRDD.first(),\"where\", \"'\"+movieRDD.first()[0]+\"'\", \"is the key and\", \"'\"+str(movieRDD.first()[1])+\"'\",\"is a 'fake' value\"\n\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "(u'movie:1411238', 1) where 'movie:1411238' is the key and "
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "'1' is a 'fake' value\n"
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## We use the fake value '1' because reducing by key using the movieId key summing up every '1' \n## will give back the times each movie is consumed\n## ReduceByKey works this way:\n## it finds a couple of line with the same key T1 = (k1,x)      T2 = (k2,y)\n## it combine the values with a specified function, in the example it sums them returning a new line T3 = (k1, x+y).\n## It goes on until there are no more lines with the same key.\n## Using top we can extract the top lines\n\nmovieRDD.reduceByKey(lambda x,y: x+y).top(5,key=lambda x: x[1])",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": "[(u'movie:1623205', 13),\n (u'movie:1024648', 11),\n (u'movie:1790885', 10),\n (u'movie:1907668', 9),\n (u'movie:1707386', 8)]"
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Advanced Tutorial: collaborative filtering with Spark!!!"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Initialization: base methods"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## We need to create a reduceByKey function that allows us to append the values in a list.\n## To do that, first we need to transform each value in a list with only one element, the value itself.\n## We use map(lambda x: createList(x)) for this purpose.\n## To append each value of each list to the others, we use lambdalist.\n## We need to do that because we cannot know the \"state\" of each line during a reduceByKey.\n\ndef create_list(value, count=1):\n    result = list()\n    for k in range(count):\n        result.append(value)\n    return result\n\ndef lambdalist(x,y):\n    for k in x:\n        y.append(k)\n    return y\n\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Computation of the cosine similarity values for each couple of movies"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Creation of the normalization matrix"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import numpy as np\n## norm(line) = sqrt ( sum ( a_i ^2)) for a_i from line\n## to compute the norm you must divide the process in 4 step:\n## start with parsedDataRDD\n## 1. parse tha data to have the format (movieID,rating)\n## 2. compute the pow2 of each rating (movieID,rating) ==(map)==> (movieID,rating^2)\n## 3. sum each rating^2 by key (hint: I would use reduce by key)\n## 4. each sum must be root squared\nnormMatrixRDD = parsedDataRDD ##put your code here\n\n\nnormMatrixRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## once we have a normalized lookup PairRDD, we need to create a similar RDD with also the userId field\n## Now you should create an RDD with this format (u'movie:1411238', (u'user:3462', 6))\n## Start with parsedDataRDD\nsparseMatrixRDDelements = parsedDataRDD\nsparseMatrixRDDelements.first()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Computing the normalised sparse matrix (user, item, norm_rating)"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## Now we have \n## sparseMatrixRDDelements =  (u'movie:1411238', (u'user:3462', 6))\n## normMatrixRDD = (u'movie:1216492', 7.0)\n## How can we compute the normalised value of each rating?\n## Firstly I would use a ...\n\nnormSparseMatrixRDDelements = sparseMatrixRDDelements ## add your code here \nnormSparseMatrixRDDelements.first()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## then, we compute the normalised value as rating / (shrink value + norm).\n## I would use a simple map\nshrink = 0.5\nnormSparseMatrixRDDelements = sparseMatrixRDDelements\n\nnormSparseMatrixRDDelements.first()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Compute the cosine similarity in a disaggregated way"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## first we make the cartesian product between each element of the normalised sparse matrix with theirselves\nitem_itemRDD = normSparseMatrixRDDelements ##put you code here\nitem_itemRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## second, we filter out rating on the same movie or on different movie by different users.\n## We need to sum the multiplication of each couple of rating of the same user on different movies. \nitem_itemRDD = normSparseMatrixRDDelements ##put you code here\n\n##item_itemRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## once we selected the right commutations, we multiplicate the normalised ratings and sum all the values with reduceByKey\nitem_itemRDDelements = normSparseMatrixRDDelements  ##put you code here\n       \n\nitem_itemRDDelements.first()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## in the end, we group results to have (movie_i, [movie_j, cos_sim(movie_i,movie_j)])\ncosSimilaritiesRDD = item_itemRDDelements ##put you code here\n\ncosSimilaritiesRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Recommendation"
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "A basic way to use the cosine similarity is to dot product the rating vector of each user with the cosine similarity matrix, rank the results and recommend the top n movies.\nThus\n1) we need to collect user ratings in the train set\n2) we need to compute the dot product\n3) we need to extract the top n\n4) we need to evaluate the recommendation with the test set"
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Parsing again the train set"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## We need to create this structure\n## userId, [(movie1, rating1),...], set(movie1,..)\n## We need to know each rating for the dot product and the set of watched movies to avoid to recommend already seen movies\n\ndef create_Dict(x,pos=1,key=0,value=1):\n    dic = {}\n    for el in x[pos]:\n        dic[el[key]] = el[value]\n    return dic\n\n\n    \nuserEventRDD = parsedDataRDD.map(lambda x: (readJson(x[4], 'subject'),create_list((readJson(x[4], 'object')\n                                                                                   ,readJson(x[3], 'rating')))))\\\n                            .reduceByKey(lambda x,y: lambdalist(x,y))\\\n                            .map(lambda x: (x[0],( create_Dict(x))))\nuserEventRDD.persist()              \nuserEventRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": "(u'user:1612',\n {u'movie:0071571': 8,\n  u'movie:0079073': 1,\n  u'movie:0108255': 2,\n  u'movie:0187078': 7,\n  u'movie:0277371': 6,\n  u'movie:0390521': 4,\n  u'movie:0450259': 10,\n  u'movie:0497373': 8,\n  u'movie:0867271': 1,\n  u'movie:1409024': 8})"
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "The cartesian product create an RDD with this structure:\nmovie = x[1][0]\nuser = x[0][0]\nalreadyWatchedMovies = x[0][1][1]\nratingList = x[0][1][0]\ncosList = x[1][1]"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def takeTopN(x, n=25):\n    a = x[1]\n    if len(a) < n: n = len(a)\n    return sorted(a, key=lambda x: -x[1])[0:n] \n    \ndef flattener(x):\n    result = list()\n    for k in x[1]:\n        result.append((x[0],k))\n    return result\n## we want to mantain only product where the recommendable item is not in the alraedy watched list but the second movie\n## in the cosSimilaritiesRDD ( cosSimilaritiesRDD : movie1,(movie2,cosSim(movie1,movie2 ) is in the already watched list.\n## Thus, we compute rating*cosSim value, we sum the score for each movie for each user, we compute the top n recommendation for each\n## user and we flatten the result to have (user,(movie, score)) structure.\n## The strange flattening is useful to join them with the user events in the test set for a super-Spark-style recall\n## and precision computation.\n\nrecommendationRDD = userEventRDD.cartesian(cosSimilaritiesRDD).filter(lambda x: x[1][0] not in x[0][1] and x[1][1][0] in x[0][1])\\\n                                .map(lambda x: (x[0][0]+\"_\"+x[1][0],x[1][1][1] * x[0][1][x[1][1][0]]))\\\n                                .reduceByKey(lambda x,y: x+y)\\\n                                .map(lambda x: (x[0].split(\"_\")[0],create_list((x[0].split(\"_\")[1],x[1]))))\\\n                                .reduceByKey(lambda x,y: lambdalist(x,y)).map(lambda x: (x[0],takeTopN(x)))\\\n                                .map(lambda x: (flattener(x))).flatMap(lambda x: x)\n                \n\nrecommendationRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": "(u'user:1340', (u'movie:0399295', 5.6957807324408529))"
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Reading and parsing test file"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "readFileTest = sc.textFile('/opt/tmp/movietweeting/evaluation/split/method_rnd_value_0.75_from_10_to_100/test/relation.dat')\nparsedDataTestRDD = readFileTest.filter(lambda x: \"EOF\" not in x).map(lambda x: x.split(\"\\t\"))\\\n                                .map(lambda x: (readJson(x[4],'subject'),(readJson(x[4],'object'),readJson(x[3],'rating'))))\nparsedDataTestRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": "(u'user:32', (u'movie:0118799', 5))"
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## We want to compute the recall as number of hits among recommended items / number of consumed items\n## We need to compute the number of hits per user to join them with the consumed items RDD\nrecommendationsHitsRDD = parsedDataTestRDD.join(recommendationRDD).filter(lambda x: x[1][0][0] == x[1][1][0])\\\n            .map(lambda x: (x[0],1)).reduceByKey(lambda x,y: x+y )\nrecommendationsHitsRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": "(u'user:1674', 1)"
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## We need to compute the number of consumed items by the user\nuserEventsRDD = parsedDataTestRDD.map(lambda x: (x[0],1)).reduceByKey(lambda x,y: x+y)\nuserEventsRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": "(u'user:1340', 4)"
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## Joining userEventsRDD and recommendationsHitsRDD we obtain in the same line the number of \n## correct recommendations and the number of consumed items.\n## The output of userEventsRDD.join(recommendationsHitsRDD) is something like (user, (#correctRecommendation,#consumedItems)).\n## The output of recallRDD is something like (user, #correctRecommendation/#consumedItems)\n## THe sum of this value / the number of elements of the RDD is the Recall\nrecallRDD = userEventsRDD.join(recommendationsHitsRDD).map(lambda x: float(x[1][1])/x[1][0])\nrecallAtN = recallRDD.sum()/recallRDD.count()\nprint \"Recall:\",recallAtN",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Recall: 0.253216374269\n"
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## To compute precision, we need to know the number of recommendation per user\nrecomCountRDD = recommendationRDD.map(lambda x: (x[0],1)).reduceByKey(lambda x,y: x+y)\nrecomCountRDD.first()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": "(u'user:1340', 25)"
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## Same as recall\nprecisionRDD = recomCountRDD.join(recommendationsHitsRDD).map(lambda x: float(x[1][1])/x[1][0])\nprecision = precisionRDD.sum()/precisionRDD.count()\nprint \"Precision:\",precision",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Precision: 0.0466666666667\n"
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
